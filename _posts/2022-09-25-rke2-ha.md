---
layout: post
title: "RKE2 HA Deployement with no external Load Balancer"
date: 2025-09-17 10:00:00 +0900
categories: [k8s]
tags: [k8s, k3s, rancher, containers, linux]
comments: true
---

# RKE2 HA Deployement with no external Load Balancer

> This article is still a mess. Please don't use it, they are rough notes. I will be publishing a new article soon on K3S + KUBE-VIP + Longhorn + MetalLB 
{: .prompt-danger }


First setup some environmental varibles. The top three lines should be customized to your own environment. 
```bash
# Environment Varibles
export VIP=10.11.240.210 # <- Load balancer virtual IP address
export TAG=v0.5.0  # <- Version of kube-vip to install
export INTERFACE=ens18 # <- Name of your OS interface for the virtual IP to associate to. 
export CONTAINER_RUNTIME_ENDPOINT=unix:///run/k3s/containerd/containerd.sock
export CONTAINERD_ADDRESS=/run/k3s/containerd/containerd.sock
export PATH=/var/lib/rancher/rke2/bin:$PATH
echo 'export PATH=/var/lib/rancher/rke2/bin:$PATH' >> ~/.bashrc

export KUBECONFIG=/etc/rancher/rke2/rke2.yaml
echo "export KUBECONFIG=/etc/rancher/rke2/rke2.yaml" >> ~/.bashrc


```

## Install rke2

- Create directories <br>
`mkdir -p /etc/rancher/rke2`
- Setup the config.yaml file to support SAN names
`/etc/rancher/rke2/config.yaml`
```yaml
tls-san:
- rke2-ctl1
- rke2-ctl1.karubits.local
- rke2-vip
- rke2-vip.karubits.local
- 10.11.240.210 # kube-vip - Virtual IP address
- 10.11.241.211 # Controller 1 IP Address

disable: rke2-ingress-nginx
#cni:
#- cilium
```
- Then install rke2 <br>
`curl -sfL https://get.rke2.io | sh -`
- Enable and start the service (can take a while)
```shell
systemctl enable rke2-server && systemctl start rke2-server && systemctl status rke2-server.service --no-pager
```
- For conconvience lets up a symbolic link to kubectl. 
```bash
ln -s $(find /var/lib/rancher/rke2/data/ -name kubectl) /usr/local/bin/kubectl
```
- for convinence run the following to add a alias for kubectl and autocompletion
```
echo 'alias k=/usr/local/bin/kubectl' >>~/.bashrc
echo 'source <(kubectl completion bash)' >>~/.bashrc
echo 'complete -o default -F __start_kubectl k' >>~/.bashrc
source ~/.bashrc
```
- Check to see if the controller node is read <br>
`k get nodes`

## kube-vip installation

- Pull kube-vip RBAC manifest <br>
`curl -s https://kube-vip.io/manifests/rbac.yaml > /var/lib/rancher/rke2/server/manifests/kube-vip-rbac.yaml`

- pull image <br>
`crictl pull docker.io/plndr/kube-vip:$TAG`

- create alias <br>
on k3s `ctr` is a link to `k3s` which has the namespace set by default but on rke2 we have to specify the namespace </br>
```shell
alias kube-vip="ctr --namespace k8s.io run --rm --net-host docker.io/plndr/kube-vip:$TAG vip /kube-vip"
echo "alias kube-vip='ctr --namespace k8s.io run --rm --net-host docker.io/plndr/kube-vip:$TAG vip /kube-vip'" >> ~/.bashrc
```


- generate manifest
```bash
kube-vip manifest daemonset \
    --arp \
    --interface $INTERFACE \
    --address $VIP \
    --controlplane \
    --leaderElection \
    --taint \
    --services \
    --inCluster | tee /var/lib/rancher/rke2/server/manifests/kube-vip.yaml
```
- Confirm to see if its running and up <br>
 `k get po -n kube-system | grep kube-vip`
- Check the logs <br>
 `k logs $(k get po -n kube-system | grep kube-vip | awk '{ print $1 }') -n kube-system --tail 1`
- make sure the VIP is responding to ping <br>
`ping $VIP`

Now that the VIP is up and running we can start to connect our other two control nodes. On controller 1 you will need to retreive the automatic generated token to add to your config.yaml of the other nodes. <br>
```bash
cat /var/lib/rancher/rke2/server/token
K10f1e88b38b999e6f5ebb6300cceaa175d9dbb2e2eb5264f323759b7418016cda4::server:a32ba55c15cc12aec2f831e7f49e10f0
```

# Addational control nodes


First setup some environmental varibles. The top three lines should be customized to your own environment. 
```bash
# Environment Varibles
export VIP=10.11.240.210 # <- Load balancer virtual IP address
export TAG=v0.5.0  # <- Version of kube-vip to install
export INTERFACE=ens18 # <- Name of your OS interface for the virtual IP to associate to. 
export CONTAINER_RUNTIME_ENDPOINT=unix:///run/k3s/containerd/containerd.sock
export CONTAINERD_ADDRESS=/run/k3s/containerd/containerd.sock
export PATH=/var/lib/rancher/rke2/bin:$PATH
export KUBECONFIG=/etc/rancher/rke2/rke2.yaml
```

## Install rke2

- Create directories <br>
`mkdir -p /etc/rancher/rke2`
- Setup the config.yaml file to support SAN names
`/etc/rancher/rke2/config.yaml`
```yaml
# Control Node #2
token: K10f1e88b38b999e6f5ebb6300cceaa175d9dbb2e2eb5264f323759b7418016cda4::server:a32ba55c15cc12aec2f831e7f49e10f0
server: https://rke2-vip.karubits.local:9345
tls-san:
- rke2-ctl2
- rke2-ctl2.karubits.local
- rke2-vip
- rke2-vip.karubits.local
- 10.11.240.210 # kube-vip - Virtual IP address
- 10.11.241.212 # Controller 1 IP Address

disable: rke2-ingress-nginx
```
```yaml
# Control Node #3
token: K10f1e88b38b999e6f5ebb6300cceaa175d9dbb2e2eb5264f323759b7418016cda4::server:a32ba55c15cc12aec2f831e7f49e10f0
server: https://rke2-vip.karubits.local:9345
tls-san:
- rke2-ctl3
- rke2-ctl3.karubits.local
- rke2-vip
- rke2-vip.karubits.local
- 10.11.240.210 # kube-vip - Virtual IP address
- 10.11.241.213 # Controller 1 IP Address

disable: rke2-ingress-nginx
```
- Then install rke2 <br>
`curl -sfL https://get.rke2.io | sh -`
- Enable and start the service (can take a while)
```shell
systemctl enable rke2-server && systemctl start rke2-server
```
- Check to see if the controller node is read <br>
`kubectl get nodes`
- For conconvience lets up a symbolic link to kubectl. 
```bash
ln -s $(find /var/lib/rancher/rke2/data/ -name kubectl) /usr/local/bin/kubectl
alias k=kubectl
```
- Confirm nodes have come up and are in a ready state. 
```bash
root@rke2-ctl1:~# kubectl get nodes
NAME        STATUS   ROLES                       AGE     VERSION
rke2-ctl1   Ready    control-plane,etcd,master   22m     v1.24.4+rke2r1
rke2-ctl2   Ready    control-plane,etcd,master   3m55s   v1.24.4+rke2r1
rke2-ctl3   Ready    control-plane,etcd,master   3m3s    v1.24.4+rke2r1
```
- You should also see that the kube-vip has scaled to all three control nodes. 
```bash
root@rke2-ctl1:~# k get po -n kube-system | grep kube-vip
kube-vip-ds-5cpwp                                       1/1     Running     0          6m9s
kube-vip-ds-lk6nb                                       1/1     Running     0          5m12s
kube-vip-ds-trzp7                                       1/1     Running     0          21m
```



# Install helm

- Check for the latest release over here [Helm Github Repo / Releases](https://github.com/helm/helm/releases)

```shell
HELM_VER=3.1.0
wget -O /tmp/helm-v$HELM_VER-linux-amd64.tar.gz https://get.helm.sh/helm-v$HELM_VER-linux-amd64.tar.gz
tar -xvf /tmp/helm-v$HELM_VER-linux-amd64.tar.gz -C /tmp/
mv /tmp/linux-amd64/helm /usr/bin/
```

# Install cert-manager

- Create the name space for cert-manager <br>
`kubectl create namespace cert-manager`

- Add the Jetstack Helm repository <br>
`helm repo add jetstack https://charts.jetstack.io`

- Update your local Helm chart repository cache  <br>
`helm repo update`

- Install the cert-manager Helm chart 
```
helm install cert-manager jetstack/cert-manager \
  --namespace cert-manager \
  --version v1.9.1
```
- I did notice the command above times out but still seems to deploy. 
- Confirm <br>
`k get pods --namespace cert-manager`
-  Install the CustomResourceDefinition resources separately  <br>
`kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v1.9.1/cert-manager.crds.yaml`

# Lets install rancher (GUI)



- Create a name space  </br>
`kubectl create namespace cattle-system`
```
helm repo add rancher-stable https://releases.rancher.com/server-charts/stable
helm repo update
helm install rancher rancher-stable/rancher \
--namespace cattle-system \
--set hostname=rke2-vip.mujin.co.jp \
--set bootstrapPassword=admin \
--set ingress.tls.source=rancher \
--set replicas=3
```

- Confirm rollout was sucessful
```shell
# kubectl -n cattle-system get deploy rancher
deployment "rancher" successfully rolled out


# kubectl -n cattle-system rollout status deploy/rancher
NAME      READY   UP-TO-DATE   AVAILABLE   AGE
rancher   3/3     3            3           3m59s
```







<br>


references:
1. [HA Kubernetes with RKE2, kube-vip, and Rancher (Youtube)](https://www.youtube.com/watch?v=QqSgiezqMAA)
1. [Notes and configs for the above](https://gitlab.com/monachus/channel/-/tree/master/resources/2021-09-07-ha-rke2-kube-vip-rancher)
1. [Install rancher offical documentation](https://docs.ranchermanager.rancher.io/pages-for-subheaders/install-upgrade-on-a-kubernetes-cluster)
1. [Install cert-manager offical documentation](https://artifacthub.io/packages/helm/cert-manager/cert-manager) 
2. [On-Prem RKE2 api-server HA with Kube-VIP](https://gist.github.com/bgulla/7a6a72bdc5df6febb1e22dbc32f0ca4f)
